{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Lab 7 - Support Vector Machine"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.\n",
    "Please answer these questions which are related to `SVM`. Refer the lecture notes titled `“Support Vector Machine”` and `“Perceptron”` before start the assignment"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "1.1 In SVM what is the meaning of margin? Which are the equations of the two margin hyperplans H+ and H- ? (1 Mark)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In SVM `Margin` is the distance between the line and the closest data points (margin hyperplanes H+ and H-)\n",
    "<br><br>\n",
    "The equations of the two margin hyperplans:<br>\n",
    "<br>\n",
    "H+: WX + b = +1  <br>\n",
    "H-: WX + b = -1"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "1.2 Consider the three linearly separable two-dimensional input vectors in the following figure. Find the linear SVM that optimally separates the classes by maximizing the margin. (1 Mark)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"https://cdn.discordapp.com/attachments/941943020578820136/951319829825060894/Screen_Shot_2022-03-09_at_10.24.39_PM.png\" width=50% alt=\"figure\">\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The 3 points on the given figure represents support vectors.<br>\n",
    "The margin hyperplan H+ is the line that passes throught the positive points <br>\n",
    "The margin hyperplan H- is parallel from H+ and passes through the negative point.<br>\n",
    "The decision boundary is the line in the center, which is halfway between H+ and H-.<br>\n",
    "The equation of the decision boundary is `-x+2=0`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "1.3 What is a kernel function? (1 Mark)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<dl>\n",
    "<dt>Kernel</dt>\n",
    "<dd>- method of using linear classifier to solve a non-linear problem <i>(Kernel Trick Method)</i></dd> \n",
    "<dd>- Function that is used in place of a \"dot product\" between two vectors</dd>\n",
    "<dd>- Transforming linearly inseparable data to linearly separable ones</dd>\n",
    "</dl>\n",
    "<br>\n",
    "\n",
    "<dl>\n",
    "<dt>Kernel Functions</dt>\n",
    "<dd>- Used to implicitly map to a new feature space <i>(Based on dot product)</i></dd> \n",
    "<dd>- It is important as it summarizes all the data via the kernel matrix.</dd>\n",
    "<dd>- Used as parameters in SVM codes to determine the shape of the hyperplane and decision boundary <em>(Does all the hard work without complex calculations)</em> </dd>\n",
    "</dl>\n",
    "\n",
    "<br>\n",
    "Kernel types:\n",
    "<ul>\n",
    "    <li> Linear</li>\n",
    "    <li> Polynomial</li>\n",
    "    <li> Gaussian RBF</li>\n",
    "    <li> Sigmoid </li>\n",
    "    <li>Chi-squared</li>\n",
    "</ul>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<hr>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "#Import\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Heart Disease Dataset\n",
    "\n",
    "<br>\n",
    "<b>Heart Disease Dataset:</b> Here, is the link for heart disease dataset of patients. <a>http://archive.ics.uci.edu/ml/datasets/Heart+Disease</a> \n",
    "<br>\n",
    "After going to this link you will find two folders: \n",
    "<li>One: Data Folder</li> \n",
    "<li>two: Dataset description.</li> </em> It is better to use processed cleveland data. \n",
    "<br>\n",
    "<br>\n",
    "In the dataset description folder, you will find the description about the columns’ names referring to the 14 column of the dataset as the following: <strong>The last one attribute (number 14) is the result. </strong> Include your R source code of regression analysis, training and generating results. Here are the example of attributes and their Information (please see data set documents for more details)\n",
    "\n",
    "<ol>\n",
    "<li> #3 (age) </li>\n",
    "<li> #4 (sex) </li>\n",
    "<li> #9 (cp) </li>\n",
    "<li> #10 (trestbps)</li> \n",
    "<li> #12 (chol)</li>\n",
    "<li> #16 (fbs) </li>\n",
    "<li> #19 (restecg) </li>\n",
    "<li> #32 (thalach) </li>\n",
    "<li> #38 (exang) </li>\n",
    "<li> #40 (oldpeak)</li>\n",
    "</ol> .........\n",
    "<li>13. #51 (thal)</li>  \n",
    "<li>14. #58 (num)</li>  \n",
    "<br>\n",
    "--------------------------->result <br> \n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "#read in heart disease data\n",
    "heartDiseaseData = pd.read_csv('heart-disease-dataset1.csv')\n",
    "heartDiseaseData.describe()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>tresbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.438944</td>\n",
       "      <td>0.679868</td>\n",
       "      <td>3.158416</td>\n",
       "      <td>131.689769</td>\n",
       "      <td>246.693069</td>\n",
       "      <td>0.148515</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>149.607261</td>\n",
       "      <td>0.326733</td>\n",
       "      <td>1.039604</td>\n",
       "      <td>1.600660</td>\n",
       "      <td>0.937294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.038662</td>\n",
       "      <td>0.467299</td>\n",
       "      <td>0.960126</td>\n",
       "      <td>17.599748</td>\n",
       "      <td>51.776918</td>\n",
       "      <td>0.356198</td>\n",
       "      <td>0.994971</td>\n",
       "      <td>22.875003</td>\n",
       "      <td>0.469794</td>\n",
       "      <td>1.161075</td>\n",
       "      <td>0.616226</td>\n",
       "      <td>1.228536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>275.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age         sex          cp     tresbps        chol         fbs  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean    54.438944    0.679868    3.158416  131.689769  246.693069    0.148515   \n",
       "std      9.038662    0.467299    0.960126   17.599748   51.776918    0.356198   \n",
       "min     29.000000    0.000000    1.000000   94.000000  126.000000    0.000000   \n",
       "25%     48.000000    0.000000    3.000000  120.000000  211.000000    0.000000   \n",
       "50%     56.000000    1.000000    3.000000  130.000000  241.000000    0.000000   \n",
       "75%     61.000000    1.000000    4.000000  140.000000  275.000000    0.000000   \n",
       "max     77.000000    1.000000    4.000000  200.000000  564.000000    1.000000   \n",
       "\n",
       "          restecg     thalach       exang     oldpeak       slope      result  \n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000  \n",
       "mean     0.990099  149.607261    0.326733    1.039604    1.600660    0.937294  \n",
       "std      0.994971   22.875003    0.469794    1.161075    0.616226    1.228536  \n",
       "min      0.000000   71.000000    0.000000    0.000000    1.000000    0.000000  \n",
       "25%      0.000000  133.500000    0.000000    0.000000    1.000000    0.000000  \n",
       "50%      1.000000  153.000000    0.000000    0.800000    2.000000    0.000000  \n",
       "75%      2.000000  166.000000    1.000000    1.600000    2.000000    2.000000  \n",
       "max      2.000000  202.000000    1.000000    6.200000    3.000000    4.000000  "
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Cleaning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "print(\"Number of missing data:\",heartDiseaseData.isna().any().sum())\n",
    "print(\"Number of duplicate data:\",heartDiseaseData.duplicated().sum())\n",
    "#replacing all the '?' to 0\n",
    "heartDiseaseData = heartDiseaseData.replace('?',0)\n",
    "\n",
    "#change object type to int\n",
    "heartDiseaseData['thal'] = heartDiseaseData['thal'].astype(float)\n",
    "heartDiseaseData['ca'] = heartDiseaseData['ca'].astype(float)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of missing data: 0\n",
      "Number of duplicate data: 0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<hr>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. \n",
    "Compare Neural Network and SVM in Classification of heart disease data set in Python language. You can use the sklearn Python library to implement both Neural Networks and SVM. <br><br>For `SVM`, build the model by changing the `different kernels` such as `Linear`, `Gaussian` and `Sigmoid` and note down the <u>model accuracy</u>. <br> Similarly, use `Stochastic Gradient Descent` and `Adam Gradient Descent` to build the **multi-layer Neural Network** and note down the <u>model accuracy</u> for each. <br><br>Finally, tell us which model performs better and why?\n",
    "(5 Marks)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "from sklearn.preprocessing import scale\n",
    "\n",
    "X = heartDiseaseData.drop(['result'],axis=1)\n",
    "Y = heartDiseaseData['result']\n",
    "\n",
    "#standardized data set\n",
    "X = scale(X)\n",
    "X_train, X_test, y_train,y_test = train_test_split(X,y,test_size=0.2, random_state=1)\n",
    "\n",
    "\n",
    "print('----------------SVM Classification---------------------')\n",
    "clf = svm.SVC(kernel ='linear')\n",
    "clf.fit(X_train,y_train)\n",
    "print('Linear Kernel Accuracy:', clf.score(X_test,y_test))\n",
    "\n",
    "clf = svm.SVC(kernel ='rbf')\n",
    "clf.fit(X_train,y_train)\n",
    "print('Gaussian RBF Kernel Accuracy:', clf.score(X_test,y_test))\n",
    "\n",
    "clf = svm.SVC(kernel ='sigmoid')\n",
    "clf.fit(X_train,y_train)\n",
    "print('Sigmoid Kernel Accuracy:', clf.score(X_test,y_test))\n",
    "\n",
    "#----------Multi-layer Neural Network----------------\n",
    "print('\\n----------------Multi-layer Neural Network---------------------')\n",
    "clf = MLPClassifier(solver='sgd',random_state=1,max_iter=1000)\n",
    "clf.fit(X_train,y_train)\n",
    "print('Stochastic Gradient Descent Accuracy:', clf.score(X_test,y_test))\n",
    "\n",
    "clf = MLPClassifier(solver='adam',random_state=1,max_iter=1000)\n",
    "clf.fit(X_train,y_train)\n",
    "print('MLP Adam Gradient Descent Accuracy:', clf.score(X_test,y_test))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "----------------SVM Classification---------------------\n",
      "Linear Kernel Accuracy: 0.639344262295082\n",
      "Gaussian RBF Kernel Accuracy: 0.6229508196721312\n",
      "Sigmoid Kernel Accuracy: 0.6229508196721312\n",
      "\n",
      "----------------Multi-layer Neural Network---------------------\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Stochastic Gradient Descent Accuracy: 0.6229508196721312\n",
      "MLP Adam Gradient Descent Accuracy: 0.5737704918032787\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "|Model|Kernel|Accuracy|\n",
    "|--------|-----------|----------------|\n",
    "|SVM Classification|Linear |0.64|\n",
    "|SVM Classification|RBF|0.62|\n",
    "|SVM Classification|Sigmoid|0.62|\n",
    "|Multi-Layer Neural Network|Stochastic Gradient Descent|0.62|\n",
    "|Multi-Layer Neural Network|Adam Gradient Descent|0.57|"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<br>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Results\n",
    "Based on the results, the model accuracy for `SVM Classification` is higher than Neural Network.\n",
    "we can see that `Linear Kernel accuracy` is `0.64` which is the highest accuracy out of all the models and beating the Neural network values (`0.62` and `0.57`). The other SVM classifications are also very close and slightly higher than the Neural Network models.\n",
    "<br> <br>\n",
    "\n",
    "## Explanation\n",
    "Some reasons why `SVM` might be better than Neural Networks is that SVMS are generally very `fast` to train since SVM uses a `subset of dataset` as training data, whereas for `Neural networks` it is dependent on the order that the data is presented so it is required to `process` the `entire` training dataset. Therefore it takes a bit of time and it is also expensive in the case of restarting training and initializing the data.\n",
    "<br>\n",
    "\n"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.3",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.3 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "398dc28c06ad810e77de546bbdfa897a6ee0b83e59a5207339dda01a7843e01d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}